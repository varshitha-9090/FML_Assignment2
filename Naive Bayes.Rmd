---
title: "assignment_3"
author: "phani varshitha"
date: "2023-10-14"
output:
  word_document: default
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


#summary
Summary:
 Created a dummy variable named "INJURY" based on the "MAX_SEV_IR>0" variable. If "MAX_SEV_IR" is 1 or 2, If no further information is available for a recently reported accident, the initial prediction should be based on the overall proportion of accidents resulting in injury (value "Yes" in the "INJURY" variable) in the dataset. Utilized the first 24 records in the dataset and focus on "INJURY," "WEATHER_R," and "TRAF_CON_R." Create a pivot table that examines "INJURY" concerning the two predictors for these 24 records.Computed the exact Bayes conditional probabilities of an injury ("INJURY" = Yes) for each of the six possible combinations of the predictors.Classifed the 24 accidents using these probabilities with a cutoff of 0.5. Computed the Naive Bayes conditional probability of an injury given "WEATHER_R" = 1 and "TRAF_CON_R" = 1 manually.as we got the same values for the manual and navie bayes as 0.
 Runs a Naive Bayes classifier on the 24 records and two predictors. model output to obtain probabilities and classifications for all 24 records.
 Split the dataset into training (60%) and validation (40%) sets. Apply a Naive Bayes classifier on the complete training set with the relevant predictors, including "INJURY" as the response. All predictors in this case are categorical.
as required we got the confusion matrix as below
predicted no yes
      no  11   7
      yes  0   0
and got the over_error rate is 0.3888889.
By performing these tasks, we can gain insights into the predictive capabilities of the Naive Bayes classifier for accident injury prediction.

#loading the required libraries and reading the accident_data set
```{r}
library(e1071)
library(caret)
accidents_data = read.csv("C:/Users/varshitha/Downloads/accidentsFull.csv")
accidents_data$INJURY = ifelse(accidents_data$MAX_SEV_IR>0,"yes","no")

```

```{r}
# Convert variables to factor
for (i in c(1:dim(accidents_data)[2])){
  accidents_data[,i] <- as.factor(accidents_data[,i])
}
head(accidents_data,n=24)
```
#selecting the first 24 rows of the data and selecting the required varaibles

```{r}
data2 = accidents_data[1:24,c("INJURY","WEATHER_R","TRAF_CON_R")]
head(data2)
```

#making the data into a table 
```{r}
pivot_Table1 <- ftable(data2)
pivot_Table2 <- ftable(data2[,-1]) # print table only for conditions
pivot_Table1
pivot_Table2
```

#presenting the possibiltes of  6 conditional probabilties 
```{r}
# Injury = yes
y1 = pivot_Table1[3,1] / pivot_Table2[1,1] # Injury, Weather=1 and Traf=0
y2 = pivot_Table1[4,1] / pivot_Table2[2,1] # Injury, Weather=2, Traf=0
y3 = pivot_Table1[3,2] / pivot_Table2[1,2] # Injury, W=1, T=1
y4 = pivot_Table1[4,2] / pivot_Table2[2,2] # I, W=2,T=1
y5 = pivot_Table1[3,3] / pivot_Table2[1,3] # I, W=1,T=2
y6 = pivot_Table1[4,3]/ pivot_Table2[2,3] #I,W=2,T=2

# Injury = no
n1 = pivot_Table1[1,1] / pivot_Table2[1,1] # Weather=1 and Traf=0
n2 = pivot_Table1[2,1] / pivot_Table2[2,1] # Weather=2, Traf=0
n3 = pivot_Table1[1,2] / pivot_Table2[1,2] # W=1, T=1
n4 = pivot_Table1[2,2] / pivot_Table2[2,2] # W=2,T=1
n5 = pivot_Table1[1,3] / pivot_Table2[1,3] # W=1,T=2
n6 = pivot_Table1[2,3] / pivot_Table2[2,3] # W=2,T=2
print(c(y1,y2,y3,y4,y5,y6))
print(c(n1,n2,n3,n4,n5,n6))
```

#computing the values for 24 accidents applying the conditon of cutoff probability = 0.5
```{r}
prob.inj <- rep(0,24)

for (i in 1:24) {
  print(c(data2$WEATHER_R[i],data2$TRAF_CON_R[i]))
    if (data2$WEATHER_R[i] == "1") {
      if (data2$TRAF_CON_R[i]=="0"){
        prob.inj[i] = y1
      }
      else if (data2$TRAF_CON_R[i]=="1") {
        prob.inj[i] = y3
      }
      else if (data2$TRAF_CON_R[i]=="2") {
        prob.inj[i] = y5
      }
    }
    else {
      if (data2$TRAF_CON_R[i]=="0"){
        prob.inj[i] = y2
      }
      else if (data2$TRAF_CON_R[i]=="1") {
        prob.inj[i] = y4
      }
      else if (data2$TRAF_CON_R[i]=="2") {
        prob.inj[i] = y6
      }
    }
  }
  
data2$prob.inj <- prob.inj

data2$pred.prob <- ifelse(data2$prob.inj>0.5, "yes", "no")

```
#computing the manually naive Bayes conditional probability of an injury given WEATHER_R = 1 and TRAF_CON_R = 1.

p(I=Y|W=1,T=1) = P(I=Y | W=1,T=1)/ P(W=1,T=1)

=(0/24)/(1/24) = 0/1
=0

#2. Run a naive Bayes classifier on the 24 records and two predictors. Check the model output to obtain probabilities and classifications for all 24 records. Compare this to the exact Bayes classification. Are the resulting classifications equivalent? Is the ranking (= ordering) of observations equivalent?
```{r}
nb <- naiveBayes(INJURY ~ TRAF_CON_R + WEATHER_R, 
                 data = data2)

nbt <- predict(nb, newdata = data2,type = "raw")
data2$nbpred.prob <- nbt[,2] # Transfer the "Yes" nb prediction
```

```{r}
library(klaR)
nb2 <- train(INJURY ~ TRAF_CON_R + WEATHER_R, 
      data = data2, method = "nb")

predict(nb2, newdata = data2[,c("INJURY", "WEATHER_R", "TRAF_CON_R")])
predict(nb2, newdata = data2[,c("INJURY", "WEATHER_R", "TRAF_CON_R")],
                                    type = "raw")
```

#Partitioning the data into training and validation sets
```{r}
set.seed(2808)  # For reproducibility
train_indices <- createDataPartition(data2,p=0.60,list = FALSE)
train_data <- data2[train_indices, ]
validation_data <- data2[-train_indices, ]
```

#Running Naive Bayes classifier on the complete training set
```{r}
nb_model <- naiveBayes(INJURY ~ WEATHER_R + TRAF_CON_R, data = train_data)
# Predict on the validation set
predicted <- predict(nb_model, newdata = validation_data)
```

# Computing the confusion matrix
```{r}
conf_matrix <- table(predicted, validation_data$INJURY)
```
#Computing the overall error of the validation set
```{r}
overall_error <- mean(predicted != validation_data$INJURY)
```

```{r}
#Print the confusion matrix and overall error
print(conf_matrix)
print(overall_error)
```
